{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b60772bf",
   "metadata": {},
   "source": [
    "Note to run these commands, you will need to run `pip install transformers` and `pip install torch`.\n",
    "\n",
    "Also, you must have `onnx` installed, but as of this writing, `pip install onnx` does not work on ARM64 devices. You must use conda to install a binary version.  https://anaconda.org/conda-forge/onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a58108",
   "metadata": {},
   "source": [
    "# Using DeBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c63ae9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"sequence\": \"The prime minister met with international leaders\",\n",
      "    \"labels\": [\n",
      "        \"politics\",\n",
      "        \"finance\",\n",
      "        \"entertainment\",\n",
      "        \"science\",\n",
      "        \"sports\",\n",
      "        \"weather\"\n",
      "    ],\n",
      "    \"scores\": [\n",
      "        0.998672604560852,\n",
      "        0.00031738588586449623,\n",
      "        0.0002589169598650187,\n",
      "        0.00025301624555140734,\n",
      "        0.0002507023746147752,\n",
      "        0.00024740086519159377\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/deberta-v3-large-zeroshot-v1\")\n",
    "sequence_to_classify = \"The prime minister met with international leaders\"\n",
    "candidate_labels = [\"weather\", \"entertainment\", \"sports\", \"finance\", \"science\", \"politics\"]\n",
    "output = classifier(sequence_to_classify, candidate_labels, multi_label=False)\n",
    "print(json.dumps(output,indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "139e0a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"sequence\": \"How many calories are in your hamburger?\",\n",
      "    \"labels\": [\n",
      "        \"marketing\",\n",
      "        \"accounting\",\n",
      "        \"sales\",\n",
      "        \"customer support\",\n",
      "        \"technical support\",\n",
      "        \"shipping and orders\"\n",
      "    ],\n",
      "    \"scores\": [\n",
      "        0.634022057056427,\n",
      "        0.12989985942840576,\n",
      "        0.06265775114297867,\n",
      "        0.0603039376437664,\n",
      "        0.06020446866750717,\n",
      "        0.052911896258592606\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/deberta-v3-large-zeroshot-v1\")\n",
    "sequence_to_classify = \"How many calories are in your hamburger?\"\n",
    "candidate_labels = [ \"sales\", \"customer support\", \"technical support\", \"accounting\", \"marketing\", \"shipping and orders\" ]\n",
    "output = classifier(sequence_to_classify, candidate_labels, multi_label=False)\n",
    "print(json.dumps(output,indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6652ae",
   "metadata": {},
   "source": [
    "# Converting the model from PyTorch to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0e5316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the model we want to convert\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"MoritzLaurer/deberta-v3-large-zeroshot-v1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7deb28dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dummy input tensor for ONNX to trace the model\n",
    "import torch\n",
    "\n",
    "# Create dummy input (batch of 1, random sentence); \"pt\" means return PyTorch tensors (input_ids and attention_mask)\n",
    "inputs = tokenizer(\"This is a dummy input for export.\", return_tensors=\"pt\")\n",
    "\n",
    "# Export the ONNX\n",
    "torch.onnx.export(\n",
    "    model,                                 # model to export\n",
    "    (inputs[\"input_ids\"], inputs[\"attention_mask\"]),  # example inputs\n",
    "    \"zero_shot_classifier.onnx\",            # output file\n",
    "    input_names=[\"input_ids\", \"attention_mask\"],    # input node names\n",
    "    output_names=[\"logits\"],                # output node name\n",
    "    dynamic_axes={\n",
    "        \"input_ids\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"attention_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"logits\": {0: \"batch_size\"}\n",
    "    },\n",
    "    opset_version=13  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98732183",
   "metadata": {},
   "source": [
    "# We'll use a preoptimized model\n",
    "https://huggingface.co/protectai/deberta-v3-large-zeroshot-v1-onnx "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe19e1e4",
   "metadata": {},
   "source": [
    "# Test ONNX locally with QNN EP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96aaaaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marketing: 0.6341\n",
      "accounting: 0.1299\n",
      "sales: 0.0627\n",
      "customer support: 0.0603\n",
      "technical support: 0.0602\n",
      "shipping and orders: 0.0529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Parameters\n",
    "text = \"How many calories are in your hamburger?\"\n",
    "candidate_labels = [\"sales\", \"customer support\", \"technical support\", \"accounting\", \"marketing\", \"shipping and orders\"]\n",
    "model_path = r\"..\\AImodels\\zero_shot_classifier.onnx\"\n",
    "tokenizer_name = \"MoritzLaurer/deberta-v3-large-zeroshot-v1\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "# Use the QNN (aka Qualcomm AI Engine Direct) execution provider\n",
    "options = onnxruntime.SessionOptions()\n",
    "session = onnxruntime.InferenceSession(model_path, sess_options=options, providers=[\"QNNExecutionProvider\"], provider_options=[{\"backend_path\":\"QnnHtp.dll\"}])\n",
    "\n",
    "# Create hypotheses\n",
    "template = \"This example is {}.\"\n",
    "hypotheses = [template.format(label) for label in candidate_labels]\n",
    "\n",
    "# Tokenize\n",
    "encoded = tokenizer(\n",
    "    [text] * len(candidate_labels),\n",
    "    hypotheses,\n",
    "    return_tensors=\"np\",\n",
    "    truncation=True,\n",
    "    padding=True\n",
    ")\n",
    "\n",
    "# Run ONNX model\n",
    "logits = session.run(\n",
    "    None,\n",
    "    {\n",
    "        \"input_ids\": encoded[\"input_ids\"],\n",
    "        \"attention_mask\": encoded[\"attention_mask\"],\n",
    "    }\n",
    ")[0]\n",
    "\n",
    "del session\n",
    "\n",
    "# Use entailment scores (index 0) and normalize with softmax\n",
    "entailment_scores = logits[:, 0]\n",
    "probs = torch.softmax(torch.from_numpy(entailment_scores), dim=0).numpy()\n",
    "\n",
    "# Zip labels and scores\n",
    "results = sorted(zip(candidate_labels, probs), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display\n",
    "for label, score in results:\n",
    "    print(f\"{label}: {score:.4f}\")\n",
    "\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e6953f",
   "metadata": {},
   "source": [
    "# Test the Azure deployment of the model\n",
    "You will need the endpoint URL and the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5f6b0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"marketing\", 0.6340243816375732], [\"accounting\", 0.12989859282970428], [\"sales\", 0.06265752762556076], [\"customer support\", 0.06030360609292984], [\"technical support\", 0.060204170644283295], [\"shipping and orders\", 0.05291173234581947]]\n"
     ]
    }
   ],
   "source": [
    "# Test deployment\n",
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://hybridaiworkspace-ukxcp.eastus.inference.ml.azure.com/score\"\n",
    "\n",
    "data = {\n",
    "    \"text\": \"How many calories are in your hamburger?\",\n",
    "    \"labels\": [ \"sales\", \"customer support\", \"technical support\", \"accounting\", \"marketing\", \"shipping and orders\" ]\n",
    "}\n",
    "\n",
    "headers = {'Content-Type':'application/json', 'Accept': 'application/json', 'Authorization':('Bearer '+ '8DgboAAfb2kVsmYvpSxclg9sQ6D4bi7hvzRm6GEBWovE0RKxZ2QpJQQJ99BEAAAAAAAAAAAAINFRAZML3Nn5')}\n",
    "\n",
    "response = requests.post(url, json=data, headers=headers)\n",
    "parsed = json.loads(response.content)      # parse the JSON string\n",
    "\n",
    "print(parsed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
